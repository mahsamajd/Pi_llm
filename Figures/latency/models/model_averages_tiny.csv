Model,Avg Transcription Time,Avg Words per Second,Avg Inference Time,Avg Tokens per Second,Avg Overall Time,Avg Other Data Processing Time
Llama3-8B-1.58-100B-tokens,9.478994,14.570413,64.189938,3.104089,73.669142,0.000208
Llama-3.2-3B_Q8_0,8.388361,14.555083,54.317887,3.282000,62.706425,0.000178
llama3.2-8B_Q2_K,7.105622,17.671058,116.256027,1.557199,123.362220,0.000571
Llama-3.2-1B_Q2_K,8.470566,14.972734,20.167831,8.882347,28.638594,0.000199
llama3.2-8B,7.102091,17.633160,1407.112652,0.146930,1414.215239,0.000497
llama3.2-8B_Q8_0,8.527814,14.701841,752.443798,0.334247,760.971800,0.000189
gemma2_Q8_0,10.577000,14.611488,43.816469,4.730234,54.394439,0.000255
Llama-3.2-3B_Q2_K,7.945329,15.402976,54.789721,3.308000,62.735596,0.000546
Llama-3.2-3B,8.477538,14.426944,266.000614,0.838000,274.478346,0.000194
gemma2_Q2_K,10.693000,14.440091,46.445788,4.323902,57.138977,0.000212
gemma2_Q4_K_M,10.651000,14.505033,40.857549,5.007134,51.506132,0.000211
Llama-3.2-1B,8.573801,14.784912,27.718569,6.381604,36.292543,0.000170
bitnet_b1_58-large,9.707809,14.201250,8.906053,21.617140,18.614046,0.000180
phi-3-Q2_k,7.651652,17.815029,74.988607,2.269204,82.640771,0.000514
llama3.2-8B_Q4_k_M,8.490202,14.734400,109.566667,1.608585,118.057067,0.000199
phi-3,9.557471,14.259900,935.905079,0.202580,945.462751,0.000201
phi-3-Q8_0,9.523994,14.269923,80.190904,2.368389,89.715097,0.000201
Llama-3.2-3B_Q4_K_M,8.437351,14.509681,50.302061,3.568000,58.739612,0.000202
Llama-3.2-1B_Q4_K_M,8.467699,14.969498,17.330810,10.074447,25.798705,0.000196
gemma2,10.697000,14.437793,75.438125,2.671857,86.136539,0.000208
Llama-3.2-1B_Q8_0,8.472614,14.963378,17.161117,10.419020,25.633927,0.000195
phi-3-Q4_K_M,9.206338,14.788456,79.183272,2.404950,88.389814,0.000201
