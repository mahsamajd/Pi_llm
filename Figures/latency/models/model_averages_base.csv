Model,Avg Transcription Time,Avg Words per Second,Avg Inference Time,Avg Tokens per Second,Avg Overall Time,Avg Other Data Processing Time
Llama-3.2-1B_Q2_K,15.279081,8.336175,20.637839,8.939105,35.917126,0.000208
llama3.2-8B_Q8_0,15.470286,8.156114,594.010673,0.339710,609.481222,0.000263
phi-3-Q8_0,17.298021,7.849436,80.671220,2.344010,97.969449,0.000208
Llama-3.2-1B,15.265304,8.411119,29.739198,6.119932,45.004668,0.000166
Llama-3.2-1B_Q4_K_M,15.292542,8.321103,17.387068,10.079099,32.679790,0.000183
Llama-3.2-3B_Q2_K,13.491246,9.051857,53.548212,3.286000,67.040008,0.000549
phi-3-Q4_K_M,16.803633,8.081748,79.708712,2.387138,96.512535,0.000188
gemma2_Q8_0,19.166000,7.975105,42.181619,4.841900,61.348786,0.000242
phi-3,17.042761,8.002652,934.529641,0.203575,951.572569,0.000165
llama3.2-8B,13.385648,9.496317,1149.489551,0.202975,1162.875357,0.000156
llama3.2-8B_Q2_K,12.945538,9.825255,118.562439,1.531102,131.508525,0.000548
Llama-3.2-3B_Q8_0,14.552901,8.410165,50.718854,3.389000,65.272012,0.000258
Llama-3.2-1B_Q8_0,15.286359,8.322122,17.262180,10.305353,32.548727,0.000188
gemma2_Q4_K_M,19.096000,7.996109,42.142411,4.919510,61.239957,0.000226
Llama3-8B-1.58-100B-tokens,17.167319,8.024039,64.014610,3.064649,81.182135,0.000206
llama3.2-8B_Q4_k_M,15.112417,8.350013,107.034597,1.597923,122.147198,0.000184
Llama-3.2-3B,14.490494,8.438378,311.136920,0.629000,325.627605,0.000192
bitnet_b1_58-large,17.196991,8.032442,8.613897,21.971371,25.811069,0.000180
phi-3-Q2_k,14.415737,9.430567,76.288265,2.243371,90.704523,0.000522
gemma2_Q2_K,18.956000,8.063130,45.766651,4.454407,64.723982,0.000255
gemma2,19.035000,8.020395,67.570381,2.939649,86.605251,0.000167
Llama-3.2-3B_Q4_K_M,14.439381,8.466275,52.491760,3.473000,66.931372,0.000231
