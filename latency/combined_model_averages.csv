Model,Avg Transcription Time,Avg Words per Second,Avg Inference Time,Avg Tokens per Second,Model Type
Q2_K,15.21,7.72,40.38,4.22,Base
Llama3-8B-1.58-100B-tokens,14.93,8.58,58.84,3.15,Base
phi3_mini,16.27,8.14,183.33,0.7,Base
bitnet_b1_58-large,14.94,8.58,7.96,22.32,Base
Q8_0,15.21,7.72,39.34,4.37,Base
llama3.2,16.27,8.14,96.24,0.65,Base
K_M,15.21,7.72,36.54,4.72,Base
ggml-base,15.21,7.72,66.13,2.57,Base
llama3.2_1b,16.27,8.14,58.51,2.37,Base
phi3_mini,161.74,0.81,181.82,0.69,Medium
Q2_K,142.78,0.82,40.29,4.23,Medium
Q8_0,142.78,0.82,38.75,4.4,Medium
bitnet_b1_58-large,142.42,0.89,8.36,21.11,Medium
ggml-medium,142.78,0.82,66.3,2.55,Medium
Llama3-8B-1.58-100B-tokens,142.42,0.89,58.71,3.15,Medium
K_M,142.78,0.82,36.75,4.69,Medium
llama3.2,161.74,0.81,97.44,0.6,Medium
llama3.2_1b,161.74,0.81,59.66,2.34,Medium
Q2_K,8.36,14.1,40.22,4.3,Tiny
Llama3-8B-1.58-100B-tokens,8.3,15.34,57.71,3.23,Tiny
K_M,8.36,14.1,35.25,4.73,Tiny
ggml-tiny,8.36,14.1,69.79,2.52,Tiny
phi3_mini,8.98,14.73,218.78,0.83,Tiny
llama3.2_1b,8.98,14.73,53.36,2.15,Tiny
Q8_0,8.36,14.1,35.61,4.67,Tiny
llama3.2,8.98,14.73,90.32,0.57,Tiny
bitnet_b1_58-large,8.3,15.34,8.05,21.97,Tiny
K_M,43.71,2.67,36.81,4.73,Small
llama3.2_1b,49.75,2.65,59.59,2.42,Small
ggml-small,43.71,2.67,66.44,2.57,Small
llama3.2,49.75,2.65,89.78,0.55,Small
Q2_K,43.71,2.67,40.16,4.29,Small
phi3_mini,49.75,2.65,194.73,0.8,Small
Q8_0,43.71,2.67,36.64,4.53,Small
bitnet_b1_58-large,46.11,2.71,8.11,21.59,Small
Llama3-8B-1.58-100B-tokens,46.11,2.72,57.6,3.19,Small
